{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Wide parameter space searches and Machine learning for CW detection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installing and importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DNVFGgnpd13"
      },
      "outputs": [],
      "source": [
        "!pip install soapcw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O42RQn5RpMG_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import soapcw\n",
        "from soapcw import cw\n",
        "import h5py\n",
        "import torch\n",
        "import os"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_data(url, filename):\n",
        "    \"\"\"Fetch data from a url and save it to given file\"\"\"\n",
        "    if not os.path.isfile(filename):\n",
        "        import urllib\n",
        "        urllib.request.urlretrieve(url, filename=filename)\n",
        "    else:\n",
        "        print(\"File already exists!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs(\"data\", exist_ok=True)\n",
        "even_url = \"https://github.com/jcbayley/cwworkshop/raw/main/data/freq_100.0_104.1_8160_even.hdf5\"\n",
        "even_file = \"data/freq_100.0_104.1_8160_even.hdf5\"\n",
        "fetch_data(even_url, even_file)\n",
        "# Now for the training data\n",
        "odd_url = \"https://github.com/jcbayley/cwworkshop/raw/main/data/freq_100.0_104.1_8160_odd.hdf5\"\n",
        "odd_file = \"data/freq_100.0_104.1_8160_odd.hdf5\"\n",
        "fetch_data(odd_url, odd_file)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SOAP\n",
        "\n",
        "SOAP (Snakes On A Plane) is a method to rapidly search for long duration signals in time-frequency spectrograms which do not follow any particular frequency evolution. This has the main goal of identifying signals that may be missed by traditional searches which use information on the expected signal to search for a signal.\n",
        "\n",
        "There are multiple components to the SOAP search:\n",
        "1. Initial frequency track identification (model agnostic)\n",
        "2. ML followup to penalise instrumental lines (some model dependence)\n",
        "3. Source parameter estimation from frequency tracks (model dependence)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vAShvRRcILLH"
      },
      "source": [
        "The SOAP package also has the ability to simulate spectrograms (i.e. time-frequency power spectra) of a CW signal. These are by default injected assuming the signal time-series is in stationary Gaussian noise, however, the PSD for each SFT can be changed and a signal can also be injected into real data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp2CNTy3pzlb"
      },
      "outputs": [],
      "source": [
        "sig = cw.GenerateSignal()\n",
        "# define signal parameters\n",
        "sig.alpha = 3.310726752188296\n",
        "sig.delta = -0.8824241920781501\n",
        "sig.cosi = -0.63086\n",
        "sig.phi0 = 4.007\n",
        "sig.psi = 0.52563\n",
        "sig.f = [100.02,-1e-17,0]\n",
        "sig.tref = 946339148.816094\n",
        "#sig.h0 = 3e-24 #can be used along with a noise floor value, but we'll just just SNR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yne7-P6oD3LF"
      },
      "outputs": [],
      "source": [
        "nsft, tstart, tsft, flow, fhigh = 48*10, 931042949, 1800., 100.0,100.1\n",
        "snr = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS3rtYI6D-Ic"
      },
      "outputs": [],
      "source": [
        "spect = sig.get_spectrogram(tstart = tstart, nsft=nsft,tsft=tsft,fmin=flow,fmax=fhigh,dets=[\"H1\", \"L1\"],snr=snr)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Spectrograms are usually summed over 1 day to remove the antenna pattern modulation and increase the SNR (assuming the signal stays within a single frequency bin for a day)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VQSfUdJD-vL"
      },
      "outputs": [],
      "source": [
        "spect.sum_sfts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "1soRN3K4ERN4",
        "outputId": "19888dcd-b7aa-40e7-ce11-9fc2066f8f3d"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=2,figsize=(14,10))\n",
        "ax[0].imshow(spect.H1.norm_sft_power.T,aspect=\"auto\",origin=\"lower\",extent=[spect.epochs.min(),spect.epochs.max(),spect.frequencies.min(),spect.frequencies.max()],cmap=\"cividis\", interpolation=\"none\")\n",
        "ax[1].imshow(spect.H1.summed_norm_sft_power.T,aspect=\"auto\",origin=\"lower\",extent=[spect.epochs.min(),spect.epochs.max(),spect.frequencies.min(),spect.frequencies.max()],cmap=\"cividis\", interpolation=\"none\")\n",
        "ax[0].set_xlabel(\"GPS time [s]\",fontsize=20)\n",
        "ax[0].set_ylabel(\"Frequency [Hz]\",fontsize=20)\n",
        "ax[1].set_xlabel(\"GPS time [s]\",fontsize=20)\n",
        "ax[1].set_ylabel(\"Frequency [Hz]\",fontsize=20)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The transition matrix defines the constraints that are placed on the track as it iterates between one time step and the next. In this case we are using multiple detectors therefore there are three components to the transition matrix. (up/down probability, geocenter to detector 1 probability, geocenter to detector 2 probability)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmq5qWKrNf7_"
      },
      "outputs": [],
      "source": [
        "transition_matrix = soapcw.tools.transition_matrix_2d(1, 1e200,1e200)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The SOAP algorithm can then be run by inputting the two normalised and summed spectrograms and the transition matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj_tnL39H2g9"
      },
      "outputs": [],
      "source": [
        "soapout = soapcw.two_detector(transition_matrix, spect.H1.summed_norm_sft_power, spect.H1.summed_norm_sft_power)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=1,figsize=(14,5))\n",
        "ax.imshow(spect.H1.summed_norm_sft_power.T,aspect=\"auto\",origin=\"lower\",extent=[spect.epochs.min(),spect.epochs.max(),spect.frequencies.min(),spect.frequencies.max()],cmap=\"cividis\", interpolation=\"none\")\n",
        "ax.plot(spect.epochs[::48], spect.frequencies[soapout.vit_track], color=\"r\")\n",
        "ax.set_xlabel(\"GPS time [s]\",fontsize=20)\n",
        "ax.set_ylabel(\"Frequency [Hz]\",fontsize=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "NqlQwp1_NbeS",
        "outputId": "e5d958f6-70c0-403e-e737-f1d985433fe6"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(14,5))\n",
        "img=ax.imshow(np.log(soapout.vitmap.T), origin=\"lower\", aspect=\"auto\", extent=[spect.epochs.min(),spect.epochs.max(),spect.frequencies.min(),spect.frequencies.max()],cmap=\"cividis\", interpolation=\"none\")\n",
        "cbar = fig.colorbar(img, ax=ax)\n",
        "cbar.set_label(\"Log normalised viterbi stat\", fontsize=20)\n",
        "ax.set_xlabel(\"GPS time [s]\",fontsize=20)\n",
        "ax.set_ylabel(\"Frequency [Hz]\",fontsize=20)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Line aware statistic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrgBj7Q2Nc4X"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m3bBgDFZGx_7"
      },
      "source": [
        "Generating useable outputs from the search involves running on many narrow bands of data. We can do this on an example set provided. The provided data contains data with and without injections.\n",
        "\n",
        "Noise: The noise is equivalent to a Gaussian noise time series, i.e. the power spectrum is a chi2 distribution with two degrees of freedom. \n",
        "\n",
        "Signal: The signal is injected with a given SNR, the square of which is used as the non centrality parameter for the noncentral chi2 distribution. The power is spread over multiple bins.\n",
        "\n",
        "There is a third set of data here which contains some instrumental artefacts to more closely simulate real data.\n",
        "\n",
        "Each of these datasets are a reduced set, so that we can run searches in a reasonable amount of time.\n",
        "The duration is 10 days (1800s SFTs) and it covers a 4Hz frequency range (100-104 Hz), where each band in 0.02 Hz wide. As the spectrograms are summed over 1 day, this leaves us with images that are 10x36. \n",
        "\n",
        "The injected signals are all very loud with integrated SNRs in the range 30->40 over 10 days. This will allow the network to learn something with a reduced number of training examples. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One thing you will notice here is the bands have been split into an \"even\" and \"odd\" category. Each sub-band is alternately put in to each of the categories. This is so that a separate machine learning model can be trained on each and tested on the opposite, this means we are never training on testing data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCNi8CYNH2sJ"
      },
      "outputs": [],
      "source": [
        "with h5py.File(\"./data_gauss2/freq_100.0_104.1_8160_even.hdf5\",\"r\") as f:\n",
        "    print(f.keys())\n",
        "    even_stats = np.array(f[\"stats\"])\n",
        "    even_imgs = np.transpose(np.array([np.array(f[\"H_imgs\"]), np.array(f[\"L_imgs\"]), np.array(f[\"vit_imgs\"])]), (1, 0, 2, 3))\n",
        "    even_labels = np.array(f[\"labels\"])\n",
        "    even_onehotlabels = torch.nn.functional.one_hot(torch.Tensor(even_labels).to(torch.int32).long(), 2)\n",
        "    #even_snrs = np.array(f[\"pars\"])[:,np.where(list(f[\"parnames\"]) == \"snr\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with h5py.File(\"./data_gauss2/freq_100.0_104.1_8160_odd.hdf5\",\"r\") as f:\n",
        "    print(f.keys())\n",
        "    odd_stats = np.array(f[\"stats\"])\n",
        "    odd_imgs = np.transpose(np.array([np.array(f[\"H_imgs\"]), np.array(f[\"L_imgs\"]), np.array(f[\"vit_imgs\"])]), (1, 0, 2, 3))\n",
        "    odd_labels = np.array(f[\"labels\"])\n",
        "    odd_onehotlabels = torch.nn.functional.one_hot(torch.Tensor(odd_labels).to(torch.int32).long(), 2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can have a look at the data that is used in this example. We can see that this is a very small dataset with very load signal, this is to make the machine learning task later managable. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SFTs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows = 2, ncols = 10, figsize = (14, 6))\n",
        "ind=3\n",
        "for i in range(10):\n",
        "    ax[0, i].imshow(odd_imgs[i,0].T)\n",
        "\n",
        "for i in range(10):\n",
        "    ax[1, i].imshow(odd_imgs[int(len(odd_imgs)/2) + i,0].T)\n",
        "#ax.set_title(odd_labels[ind])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows = 2, ncols = 10, figsize = (14, 6))\n",
        "ind=3\n",
        "for i in range(10):\n",
        "    ax[0, i].imshow(odd_imgs[i,2].T)\n",
        "\n",
        "for i in range(10):\n",
        "    ax[1, i].imshow(odd_imgs[int(len(odd_imgs)/2) + i,2].T)\n",
        "#ax.set_title(odd_labels[ind])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SOAP can be run on all examples in this folder, we can use the included files as the lookup tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "even_soapouts = np.zeros(len(even_imgs))\n",
        "for index in range(len(even_imgs)):\n",
        "    out = soapcw.two_detector(transition_matrix, even_imgs[index][0], even_imgs[index][1])\n",
        "    # soapcw.two_detector(transition_matrix, H_imgs[index], L_imgs[index], lookup_table)\n",
        "    even_soapouts[index] = out.max_end_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "odd_soapouts = np.zeros(len(odd_imgs))\n",
        "for index in range(len(odd_imgs)):\n",
        "    out = soapcw.two_detector(transition_matrix, odd_imgs[index][0], odd_imgs[index][1])\n",
        "    # soapcw.two_detector(transition_matrix, H_imgs[index], L_imgs[index], lookup_table)\n",
        "    odd_soapouts[index] = out.max_end_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(even_soapouts[:10])\n",
        "print(even_stats[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "bins = np.linspace(min(odd_stats), max(odd_stats), 30)\n",
        "hst = ax.hist(odd_stats[even_labels == 1], bins=bins, label=\"signal\", alpha=0.5)\n",
        "hst2 = ax.hist(odd_stats[even_labels == 0], bins=bins, label=\"noise\", alpha=0.5)\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"Viterbi statistic\")\n",
        "ax.set_ylabel(\"count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "bins = np.linspace(min(odd_soapouts), max(odd_soapouts), 30)\n",
        "hst = ax.hist(odd_soapouts[even_labels == 1], bins=bins, label=\"signal\", alpha=0.5)\n",
        "hst2 = ax.hist(odd_soapouts[even_labels == 0], bins=bins, label=\"noise\", alpha=0.5)\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"Viterbi statistic\")\n",
        "ax.set_ylabel(\"count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So far we have a dataset from which we want to learn if a signal is present. This falls into the category of binary classification, where we want the model to predict how probable it is that a signal is present. When dealing with binary classification we want to minimise the Binary cross entropy between the truth and the predicted output. This is defined by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#imgshape\n",
        "print(odd_imgs.shape)\n",
        "print(even_imgs.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Setup"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can define some parameters of out model here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "in_channels = 3 #[H,L,vitmap]\n",
        "outsize = 2 # [noise_prob, signal_prob]\n",
        "n_epochs = 3000\n",
        "learning_rate = 4e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels, 4, (7,7), padding=\"same\"),\n",
        "    torch.nn.MaxPool2d((1,2)),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Conv2d(4, 4, (3,3)),\n",
        "    torch.nn.MaxPool2d((1,2)),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.AdaptiveAvgPool2d((2,2)),\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Dropout(0.4),\n",
        "    torch.nn.LazyLinear(16),\n",
        "    torch.nn.Dropout(0.4),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.LazyLinear(8),\n",
        "    torch.nn.Dropout(0.4),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.LazyLinear(outsize)\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For ease of use this can be written from a config file using SOAP, or input the configuration as a dictionary\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_config = {\n",
        "    \"model_type\": \"vitmapspectrogram\",              # what inputs are used (vitmap and spectrogram)\n",
        "    \"save_dir\": \"./\",                               # where to save model when training\n",
        "    \"learning_rate\": 1e-4,                          # the learning rate of the Adam optimiser\n",
        "    \"img_dim\": (180, 470),                          # the size of the input image\n",
        "    \"conv_layers\": [(4, 7, 2, 1), (4, 3, 2, 1)],    # the convolutional layers (num_filters, filter_size, maxpool_size, stride)\n",
        "    \"avg_pool\": 2,                                  # the size of the average pooling layer \n",
        "    \"fc_layers\": [16, 8, 2],                        # the size of the fully connected mlp layers   \n",
        "    \"dropout\": 0.4,                                 # the amount of dropout to use (default 0)\n",
        "    \"n_epochs\": 100,                                # number of epochs used for training\n",
        "    \"save_interval\": 2,                             # how many epochs to save the model after\n",
        "    \"band_types\": [\"even\", \"odd\"],                  # which bands to train on (here train an odd and an even version)\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"model\": model_config\n",
        "    \"data\": data_config\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss and Optimiser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimiser = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_batch(model, optimiser, loss_function, data, labels, train=True):\n",
        "    \"\"\"\n",
        "    Compute the loss for one batch of training/validation data. If train=True update the model.\n",
        "    Args\n",
        "    -------\n",
        "    model: \n",
        "        pytorch model\n",
        "    optimiser:\n",
        "    loss_function:\n",
        "    data: Tensor\n",
        "    labels: Tensor\n",
        "    train: bool\n",
        "        if true updates the model weights and optimiser\n",
        "    \"\"\"\n",
        "    model.train(train)\n",
        "    if train:\n",
        "        optimiser.zero_grad()\n",
        "\n",
        "    outputs = model(data)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    if train:\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "    return loss.item()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now write out simple training loop. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tr_losses = np.zeros(n_epochs)\n",
        "val_losses = np.zeros(n_epochs)\n",
        "val_inds = np.random.uniform(0, len(odd_imgs), 200).astype(int)\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    tr_loss = train_batch(cnn, optimiser, loss_fn, torch.Tensor(even_imgs[:,:]), even_onehotlabels.to(torch.float32), train=True)\n",
        "    with torch.no_grad():\n",
        "        # only use 200 of the odd bands for validation\n",
        "        val_loss = train_batch(cnn, optimiser, loss_fn, torch.Tensor(odd_imgs[val_inds,:]), odd_onehotlabels.to(torch.float32)[val_inds], train=False)\n",
        "\n",
        "    tr_losses[epoch] = tr_loss\n",
        "    val_losses[epoch] = val_loss\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch: {epoch}, loss: {tr_loss}, val_loss: {val_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we can put in images of any size \n",
        "inp = torch.randn((20,3,50,190))\n",
        "out = cnn(inp)\n",
        "print(inp.shape, out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(tr_losses)\n",
        "ax.plot(val_losses)\n",
        "ax.set_yscale(\"log\")\n",
        "#ax.set_xscale(\"log\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    odd_outputs = cnn(torch.Tensor(odd_imgs[:,:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "odd_outputs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compute how well the cnn and SOAP performs by measuring the true positive rate at a false alarm of 1%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn_99per = sorted(odd_outputs[odd_labels==0][:,0])[int(0.99*len(odd_outputs[odd_labels==0]))]\n",
        "soap_99per = sorted(odd_soapouts[odd_labels==0])[int(0.99*len(odd_outputs[odd_labels==0]))]\n",
        "print(cnn_99per.numpy(), soap_99per)\n",
        "cnn_sigfrac = sum(odd_outputs[odd_labels==1][:,1] > cnn_99per)/len(odd_outputs[odd_labels==1])\n",
        "soap_sigfrac = sum(odd_soapouts[odd_labels==1] > soap_99per)/len(odd_outputs[odd_labels==1])\n",
        "print(cnn_sigfrac.numpy(), soap_sigfrac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(ncols = 2, figsize=(14,5))\n",
        "h11 = ax[0].hist(odd_outputs[odd_labels==0][:,1], bins=np.arange(-1,50), alpha=0.5)\n",
        "h12 = ax[0].hist(odd_outputs[odd_labels==1][:,1], bins=np.arange(-1,50), alpha=0.5)\n",
        "ax[0].set_yscale(\"log\")\n",
        "h11 = ax[1].hist(torch.nn.functional.sigmoid(odd_outputs[odd_labels==0][:,1]), bins=30, alpha=0.5)\n",
        "h12 = ax[1].hist(torch.nn.functional.sigmoid(odd_outputs[odd_labels==1][:,1]), bins=30, alpha=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "soapcw",
      "language": "python",
      "name": "soapcw"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "8a5edab282632443219e051e4ade2d1d5bbc671c781051bf1437897cbdfea0f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
